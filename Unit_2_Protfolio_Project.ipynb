{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Sale Price Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports! Imports EVERYWHERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from category_encoders import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Wrangle Data \n",
    "- Here I will define a function named `wrangle` to ensure reproducibility, and to streamline the data cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrangle function\n",
    "def wrangle(filepath):\n",
    "    # read in dataframe\n",
    "    X = pd.read_csv(filepath)\n",
    "    # drop unnecessary columns\n",
    "    X.drop(columns='Market Category', axis=1, inplace=True)\n",
    "    # drop columns with '0' sale_price\n",
    "    X.drop(X[X['MSRP']==0].index, inplace=True)\n",
    "    # remove outliers\n",
    "    X.drop(X[X[\"MSRP\"] >= 500000].index, inplace=True)\n",
    "    # clean column names\n",
    "    X.rename(columns={\"Make\": \"make\",\n",
    "                      \"Model\": \"model\",\n",
    "                      \"Year\": \"year\",\n",
    "                      \"Engine Fuel Type\": \"fuel_type\",\n",
    "                      \"Engine HP\": \"horsepower\",\n",
    "                      \"Engine Cylinders\": \"cylinders\",\n",
    "                      \"Transmission_Type\": \"transmission\",\n",
    "                      \"Driven_Wheels\": \"drive_type\",\n",
    "                      \"Number of Doors\": \"doors\",\n",
    "                      \"Vehicle Size\": \"size\",\n",
    "                      \"Vehicle Style\": \"body_style\",\n",
    "                      \"highway MPG\": \"mpg_h\",\n",
    "                      \"city mpg\": \"mpg_c\",\n",
    "                      \"Popularity\": \"popularity\",\n",
    "                      \"MSRP\": \"sale_price\"}, inplace=True)\n",
    "    # create feature for age of car\n",
    "    X['vehicle_age'] = 2017 - X['year']\n",
    "    # Drop observations with `NaN` values\n",
    "    X = X.dropna()\n",
    "    # Type casting `strings` to `category`\n",
    "    cat_col = [col for col in X.select_dtypes('object').columns]\n",
    "    X[cat_col] = X[cat_col].astype('category')\n",
    "    return X\n",
    "# setting filepath to dataframe\n",
    "filepath = '../data/data.csv' \n",
    "# apply wrangle function to dataset\n",
    "cars = wrangle(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11801 entries, 0 to 11913\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   make               11801 non-null  category\n",
      " 1   model              11801 non-null  category\n",
      " 2   year               11801 non-null  int64   \n",
      " 3   fuel_type          11801 non-null  category\n",
      " 4   horsepower         11801 non-null  float64 \n",
      " 5   cylinders          11801 non-null  float64 \n",
      " 6   Transmission Type  11801 non-null  category\n",
      " 7   drive_type         11801 non-null  category\n",
      " 8   doors              11801 non-null  float64 \n",
      " 9   size               11801 non-null  category\n",
      " 10  body_style         11801 non-null  category\n",
      " 11  mpg_h              11801 non-null  int64   \n",
      " 12  mpg_c              11801 non-null  int64   \n",
      " 13  popularity         11801 non-null  int64   \n",
      " 14  sale_price         11801 non-null  int64   \n",
      " 15  vehicle_age        11801 non-null  int64   \n",
      "dtypes: category(7), float64(3), int64(6)\n",
      "memory usage: 1.0 MB\n"
     ]
    }
   ],
   "source": [
    "# confirm functionality of wrangle function\n",
    "cars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Split Data\n",
    "- Here I will separate my feature matrix from my target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Matrix Shape: (11801, 15)\n",
      "Target Vector Shape: (11801,)\n"
     ]
    }
   ],
   "source": [
    "# Separating `Feature Matrix` from `Target Vector` \n",
    "target = 'sale_price'\n",
    "y = cars[target]\n",
    "X = cars.drop(columns=target)\n",
    "# Verifying shape `Feature Matrix` and `Target Vector`\n",
    "print(f'Feature Matrix Shape: {X.shape}')\n",
    "print(f'Target Vector Shape: {y.shape}')\n",
    "# Applying training/validation split to `FM` and `TV`\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Establish Baseline\n",
    "- Being that `sale_price` is my target I will use the mean `sale_price` to establish my baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline r2: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Establish baseline \n",
    "y_mean = y.mean()\n",
    "y_pred = [y_mean] * len(y)\n",
    "y_pred\n",
    "\n",
    "# baseline mae for just guessing\n",
    "baseline_r2 = r2_score(y, y_pred)\n",
    "print(f'Baseline r2: {baseline_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  IV. Build Model\n",
    "- Here I'm building a \"quick-and-dirty\" model to see if I can beat my baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eric/anaconda3/envs/unit2/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('onehotencoder',\n",
       "                 OneHotEncoder(cols=['make', 'model', 'fuel_type',\n",
       "                                     'Transmission Type', 'drive_type', 'size',\n",
       "                                     'body_style'],\n",
       "                               use_cat_names=True)),\n",
       "                ('simpleimputer', SimpleImputer()),\n",
       "                ('standardscaler', StandardScaler()), ('ridge', Ridge())])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic linear regressor to test against baseline\n",
    "model_r = make_pipeline(OneHotEncoder(use_cat_names=True),\n",
    "                        SimpleImputer(),\n",
    "                        StandardScaler(),\n",
    "                        Ridge())\n",
    "# fit model with training data\n",
    "model_r.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2361, 11801]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-af400f51e0c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mean Absolute Error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_r2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/unit2/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unit2/lib/python3.8/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mr2_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \"\"\"\n\u001b[0;32m--> 676\u001b[0;31m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[1;32m    677\u001b[0m         y_true, y_pred, multioutput)\n\u001b[1;32m    678\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unit2/lib/python3.8/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0margument\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \"\"\"\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/unit2/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2361, 11801]"
     ]
    }
   ],
   "source": [
    "# Mean Absolute Error\n",
    "model_r2 = r2_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
