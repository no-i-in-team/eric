{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Sale Price Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports! Imports EVERYWHERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Wrangle Data \n",
    "- Here I will define a function named `wrangle` to ensure reproducibility, and to streamline the data cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrangle function\n",
    "def wrangle(filepath):\n",
    "    # read in dataframe\n",
    "    X = pd.read_csv(filepath)\n",
    "    # drop unnecessary columns\n",
    "    X.drop(columns='Market Category', axis=1, inplace=True)\n",
    "    # drop columns with '0' sale_price\n",
    "    X.drop(X[X['MSRP']==0].index, inplace=True)\n",
    "    # remove outliers\n",
    "    X.drop(X[X[\"MSRP\"] >= 500000].index, inplace=True)\n",
    "    # clean column names\n",
    "    X.rename(columns={\"Make\": \"make\",\n",
    "                      \"Model\": \"model\",\n",
    "                      \"Year\": \"year\",\n",
    "                      \"Engine Fuel Type\": \"fuel_type\",\n",
    "                      \"Engine HP\": \"horsepower\",\n",
    "                      \"Engine Cylinders\": \"cylinders\",\n",
    "                      \"Transmission_Type\": \"transmission\",\n",
    "                      \"Driven_Wheels\": \"drive_type\",\n",
    "                      \"Number of Doors\": \"doors\",\n",
    "                      \"Vehicle Size\": \"size\",\n",
    "                      \"Vehicle Style\": \"body_style\",\n",
    "                      \"highway MPG\": \"mpg_h\",\n",
    "                      \"city mpg\": \"mpg_c\",\n",
    "                      \"Popularity\": \"popularity\",\n",
    "                      \"MSRP\": \"sale_price\"}, inplace=True)\n",
    "    # create feature for age of car\n",
    "    X['vehicle_age'] = 2017 - X['year']\n",
    "    # Drop observations with `NaN` values\n",
    "    X = X.dropna()\n",
    "    # Type casting `strings` to `category`\n",
    "    cat_col = [col for col in X.select_dtypes('object').columns]\n",
    "    X[cat_col] = X[cat_col].astype('category')\n",
    "    return X\n",
    "# setting filepath to dataframe\n",
    "filepath = 'CSV/cars.csv'\n",
    "# apply wrangle function to dataset\n",
    "cars = wrangle(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11801 entries, 0 to 11913\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   make               11801 non-null  category\n",
      " 1   model              11801 non-null  category\n",
      " 2   year               11801 non-null  int64   \n",
      " 3   fuel_type          11801 non-null  category\n",
      " 4   horsepower         11801 non-null  float64 \n",
      " 5   cylinders          11801 non-null  float64 \n",
      " 6   Transmission Type  11801 non-null  category\n",
      " 7   drive_type         11801 non-null  category\n",
      " 8   doors              11801 non-null  float64 \n",
      " 9   size               11801 non-null  category\n",
      " 10  body_style         11801 non-null  category\n",
      " 11  mpg_h              11801 non-null  int64   \n",
      " 12  mpg_c              11801 non-null  int64   \n",
      " 13  popularity         11801 non-null  int64   \n",
      " 14  sale_price         11801 non-null  int64   \n",
      " 15  vehicle_age        11801 non-null  int64   \n",
      "dtypes: category(7), float64(3), int64(6)\n",
      "memory usage: 1.0 MB\n"
     ]
    }
   ],
   "source": [
    "# confirm functionality of wrangle function\n",
    "cars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Split Data\n",
    "- Here I will separate my feature matrix from my target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Matrix Shape: (11801, 15)\n",
      "Target Vector Shape: (11801,)\n"
     ]
    }
   ],
   "source": [
    "# Separating `Feature Matrix` from `Target Vector` \n",
    "target = 'sale_price'\n",
    "y = cars[target]\n",
    "X = cars.drop(columns=target)\n",
    "# Verifying shape `Feature Matrix` and `Target Vector`\n",
    "print(f'Feature Matrix Shape: {X.shape}')\n",
    "print(f'Target Vector Shape: {y.shape}')\n",
    "# Applying training/validation split to `FM` and `TV`\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Establish Baseline\n",
    "- Being that `sale_price` is my target I will use the mean `sale_price` to establish my baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MAE: 24495.238887285443\n"
     ]
    }
   ],
   "source": [
    "# Establish baseline \n",
    "mean_sale_price = y_train.mean()\n",
    "y_pred = [mean_sale_price] * len(y_train)\n",
    "# baseline mae for just guessing\n",
    "baseline_mae = mean_absolute_error(y_train, y_pred)\n",
    "print(f'Baseline MAE: {baseline_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  IV. Build Model\n",
    "- Here I'm building a \"quick-and-dirty\" model to see if I can beat my baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eric/anaconda3/envs/unit2/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('onehotencoder',\n",
       "                 OneHotEncoder(cols=['make', 'model', 'fuel_type',\n",
       "                                     'Transmission Type', 'drive_type', 'size',\n",
       "                                     'body_style'],\n",
       "                               use_cat_names=True)),\n",
       "                ('simpleimputer', SimpleImputer()),\n",
       "                ('standardscaler', StandardScaler()),\n",
       "                ('linearregression', LinearRegression())])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic linear regressor to test against baseline\n",
    "lin_reg = make_pipeline(OneHotEncoder(use_cat_names=True),\n",
    "                        SimpleImputer(),\n",
    "                        StandardScaler(),\n",
    "                        LinearRegression())\n",
    "# fit model with training data\n",
    "lin_reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Training MAE: 3463.7721635190346\n",
      "Linear Regression Validation MAE: 2282309672614174.5\n"
     ]
    }
   ],
   "source": [
    "# Mean absolute error for training and validation sets\n",
    "train_MAE = mean_absolute_error(y_train, lin_reg.predict(X_train))\n",
    "val_MAE = mean_absolute_error(y_val, lin_reg.predict(X_val))\n",
    "# return MAE\n",
    "print(f'Linear Regression Training MAE: {train_MAE}')\n",
    "print(f'Linear Regression Validation MAE: {val_MAE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression Model\n",
    "- `Ridge()` Regression model to test against baseline MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eric/anaconda3/envs/unit2/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('onehotencoder',\n",
       "                 OneHotEncoder(cols=['make', 'model', 'fuel_type',\n",
       "                                     'Transmission Type', 'drive_type', 'size',\n",
       "                                     'body_style'],\n",
       "                               use_cat_names=True)),\n",
       "                ('standardscaler', StandardScaler()),\n",
       "                ('simpleimputer', SimpleImputer()), ('ridge', Ridge())])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline for ridge regressor\n",
    "ridge_mod = make_pipeline(\n",
    "                    OneHotEncoder(use_cat_names=True),\n",
    "                    StandardScaler(),\n",
    "                    SimpleImputer(),\n",
    "                    Ridge())\n",
    "\n",
    "# fit ridge regressor with training data\n",
    "ridge_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Training MAE: 3253.240066091798\n",
      "Ridge Regression Validation MAE: 3695.326447829763\n"
     ]
    }
   ],
   "source": [
    "# Mean absolute error for training and validation sets\n",
    "ridge_train_MAE = mean_absolute_error(y_train, ridge_mod.predict(X_train))\n",
    "ridge_val_MAE = mean_absolute_error(y_val, ridge_mod.predict(X_val))\n",
    "# return MAE\n",
    "print(f'Ridge Regression Training MAE: {ridge_train_MAE}')\n",
    "print(f'Ridge Regression Validation MAE: {ridge_val_MAE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ordinalencoder',\n",
       "                 OrdinalEncoder(cols=['make', 'model', 'fuel_type',\n",
       "                                      'Transmission Type', 'drive_type', 'size',\n",
       "                                      'body_style'],\n",
       "                                mapping=[{'col': 'make',\n",
       "                                          'data_type': CategoricalDtype(categories=['Acura', 'Alfa Romeo', 'Aston Martin', 'Audi', 'BMW',\n",
       "                  'Bentley', 'Buick', 'Cadillac', 'Chevrolet', 'Chrysler',\n",
       "                  'Dodge', 'FIAT', 'Ferrari', 'Ford', 'GMC', 'Genesis',\n",
       "                  'HUM...\n",
       "                  'Regular Cab Pickup', 'Sedan', 'Wagon'],\n",
       ", ordered=False),\n",
       "                                          'mapping': Crew Cab Pickup         1\n",
       "2dr Hatchback           2\n",
       "Sedan                   3\n",
       "4dr SUV                 4\n",
       "Passenger Minivan       5\n",
       "Extended Cab Pickup     6\n",
       "Cargo Van               7\n",
       "Coupe                   8\n",
       "Regular Cab Pickup      9\n",
       "2dr SUV                10\n",
       "Wagon                  11\n",
       "Convertible            12\n",
       "4dr Hatchback          13\n",
       "Passenger Van          14\n",
       "Cargo Minivan          15\n",
       "Convertible SUV        16\n",
       "NaN                    -2\n",
       "dtype: int64}])),\n",
       "                ('simpleimputer', SimpleImputer()),\n",
       "                ('randomforestregressor', RandomForestRegressor())])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Regressor pipeline\n",
    "rfr = make_pipeline(\n",
    "            OrdinalEncoder(),\n",
    "            SimpleImputer(),\n",
    "            RandomForestRegressor())\n",
    "\n",
    "rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1760.3715712957514\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_train, rfr.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3050.652533506656\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_val, rfr.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ordinalencoder',\n",
       "                 OrdinalEncoder(cols=['make', 'model', 'fuel_type',\n",
       "                                      'Transmission Type', 'drive_type', 'size',\n",
       "                                      'body_style'],\n",
       "                                mapping=[{'col': 'make',\n",
       "                                          'data_type': CategoricalDtype(categories=['Acura', 'Alfa Romeo', 'Aston Martin', 'Audi', 'BMW',\n",
       "                  'Bentley', 'Buick', 'Cadillac', 'Chevrolet', 'Chrysler',\n",
       "                  'Dodge', 'FIAT', 'Ferrari', 'Ford', 'GMC', 'Genesis',\n",
       "                  'HUM...\n",
       "                  'Regular Cab Pickup', 'Sedan', 'Wagon'],\n",
       ", ordered=False),\n",
       "                                          'mapping': Crew Cab Pickup         1\n",
       "2dr Hatchback           2\n",
       "Sedan                   3\n",
       "4dr SUV                 4\n",
       "Passenger Minivan       5\n",
       "Extended Cab Pickup     6\n",
       "Cargo Van               7\n",
       "Coupe                   8\n",
       "Regular Cab Pickup      9\n",
       "2dr SUV                10\n",
       "Wagon                  11\n",
       "Convertible            12\n",
       "4dr Hatchback          13\n",
       "Passenger Van          14\n",
       "Cargo Minivan          15\n",
       "Convertible SUV        16\n",
       "NaN                    -2\n",
       "dtype: int64}])),\n",
       "                ('simpleimputer', SimpleImputer()),\n",
       "                ('gradientboostingregressor', GradientBoostingRegressor())])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr = make_pipeline(\n",
    "            OrdinalEncoder(),\n",
    "            SimpleImputer(),\n",
    "            GradientBoostingRegressor())\n",
    "\n",
    "xgbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5295.253146518181\n",
      "5291.792732270664\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_train, xgbr.predict(X_train)))\n",
    "print(mean_absolute_error(y_val, xgbr.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
